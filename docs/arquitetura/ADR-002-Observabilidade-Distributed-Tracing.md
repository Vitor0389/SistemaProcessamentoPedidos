# ADR-002: ImplementaÃ§Ã£o de Observabilidade com Distributed Tracing

## Status
**ACEITO** - 2024

## Contexto

Com a adoÃ§Ã£o de Event-Driven Architecture (ADR-001), o sistema passou a ser composto por mÃºltiplos serviÃ§os independentes que se comunicam de forma assÃ­ncrona atravÃ©s do Apache Kafka. Esta arquitetura distribuÃ­da traz desafios significativos de observabilidade:

### Desafios Identificados

1. **Visibilidade Fragmentada**
   - Logs dispersos em mÃºltiplos serviÃ§os
   - DifÃ­cil correlacionar operaÃ§Ãµes relacionadas
   - ImpossÃ­vel visualizar o fluxo completo de uma requisiÃ§Ã£o

2. **Debugging Complexo**
   - "Onde estÃ¡ o problema?" requer investigaÃ§Ã£o em mÃºltiplos serviÃ§os
   - Logs nÃ£o indicam relacionamento entre operaÃ§Ãµes
   - Tempo elevado para identificar root cause de falhas

3. **AnÃ¡lise de Performance**
   - ImpossÃ­vel medir latÃªncia end-to-end
   - DifÃ­cil identificar gargalos no pipeline
   - NÃ£o hÃ¡ visibilidade de tempo gasto em cada etapa

4. **ComunicaÃ§Ã£o AssÃ­ncrona**
   - Kafka adiciona camada intermediÃ¡ria
   - Contexto Ã© perdido entre producer e consumers
   - Dificulta rastreamento de eventos relacionados

### CenÃ¡rio Atual (Sem Observabilidade)

```
Cliente -> [ServiÃ§o Pedidos] -> [Kafka] -> [ServiÃ§o NotificaÃ§Ã£o]
                                        -> [ServiÃ§o Estoque]

Logs:
[pedidos]      INFO: Pedido PED-001 criado
[kafka]        INFO: Mensagem publicada no tÃ³pico pedidos
[notificacao]  INFO: NotificaÃ§Ã£o enviada
[estoque]      INFO: Estoque atualizado

âŒ Problema: Como correlacionar essas 4 linhas de log?
âŒ Problema: Quanto tempo levou do inÃ­cio ao fim?
âŒ Problema: Onde estÃ¡ o gargalo?
```

### Requisitos de Observabilidade

1. **Rastreamento End-to-End**: Visualizar toda a jornada de uma requisiÃ§Ã£o
2. **CorrelaÃ§Ã£o AutomÃ¡tica**: Agrupar logs relacionados sem esforÃ§o manual
3. **MediÃ§Ã£o de LatÃªncia**: Tempo gasto em cada etapa do processamento
4. **IdentificaÃ§Ã£o de Gargalos**: Detectar componentes lentos
5. **AnÃ¡lise de Falhas**: Entender onde e por que falhas ocorrem
6. **Baixo Overhead**: NÃ£o degradar performance do sistema
7. **VisualizaÃ§Ã£o Intuitiva**: Interface grÃ¡fica para anÃ¡lise

## DecisÃ£o

**Implementaremos Distributed Tracing usando Micrometer Tracing com Brave e Zipkin como backend de armazenamento e visualizaÃ§Ã£o.**

### Arquitetura da SoluÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP Request
       â”‚ [gera TraceId]
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ServiÃ§o Pedidos â”‚ â”€â”
â”‚ [Micrometer]    â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚           â”‚ Todos enviam
         â”‚ Kafka     â”‚ spans para
         â”‚ [propaga  â”‚ Zipkin
         â”‚  TraceId] â”‚
         â–¼           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
    â”‚ Kafka  â”‚      â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â”‚
        â”‚           â”‚
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚
   â”‚          â”‚     â”‚
   â–¼          â–¼     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Notific. â”‚ â”‚ Estoque â”‚ â”€â”˜
â”‚[Microm.]â”‚ â”‚[Microm.]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Zipkin  â”‚
    â”‚  :9411  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes da SoluÃ§Ã£o

#### 1. Micrometer Tracing
- **O que Ã©**: AbstraÃ§Ã£o de tracing para aplicaÃ§Ãµes Java
- **FunÃ§Ã£o**: API unificada independente de implementaÃ§Ã£o
- **IntegraÃ§Ã£o**: Nativa com Spring Boot 3.x

#### 2. Brave
- **O que Ã©**: ImplementaÃ§Ã£o de distributed tracing (OpenZipkin)
- **FunÃ§Ã£o**: Bridge entre Micrometer e Zipkin
- **Responsabilidades**:
  - Criar e gerenciar spans
  - Propagar contexto entre threads
  - Injetar trace context em headers HTTP e Kafka
  - Coletar timing information

#### 3. Zipkin
- **O que Ã©**: Sistema de distributed tracing
- **FunÃ§Ã£o**: Coletar, armazenar e visualizar traces
- **Features**:
  - Storage in-memory (desenvolvimento)
  - Web UI para queries
  - Dependency graph
  - Latency analysis

### Conceitos Fundamentais

#### Trace
- Representa uma operaÃ§Ã£o completa atravÃ©s do sistema
- Identificado por um **TraceId** Ãºnico (128-bit)
- Composto por mÃºltiplos spans

#### Span
- Unidade bÃ¡sica de trabalho
- Representa uma operaÃ§Ã£o individual (ex: HTTP request, Kafka send)
- ContÃ©m:
  - SpanId (64-bit)
  - ParentSpanId (para hierarquia)
  - Timestamps (inÃ­cio/fim)
  - Tags (metadata)
  - Logs (eventos)

#### Context Propagation
- TraceId e SpanId sÃ£o propagados entre serviÃ§os
- HTTP: via headers (`X-B3-TraceId`, `X-B3-SpanId`)
- Kafka: via message headers
- Permite reconstruir o fluxo completo

### Exemplo de Trace

```
TraceId: 1a2b3c4d5e6f7g8h

Span 1 [HTTP POST /api/pedidos]          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 120ms
  |
  â”œâ”€ Span 2 [validaÃ§Ã£o]                  â–ˆâ–ˆ 10ms
  |
  â”œâ”€ Span 3 [Kafka publish]              â–ˆâ–ˆâ–ˆâ–ˆ 30ms
  |
  â””â”€ Span 4 [Response]                    â–ˆ 5ms

Span 5 [Kafka consume - notificaÃ§Ã£o]         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 80ms
  |
  â””â”€ Span 6 [enviar email]                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 60ms

Span 7 [Kafka consume - estoque]             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 70ms
  |
  â”œâ”€ Span 8 [verificar disponibilidade]      â–ˆâ–ˆ 20ms
  |
  â””â”€ Span 9 [atualizar quantidade]           â–ˆâ–ˆâ–ˆ 30ms
```

## Alternativas Consideradas

### 1. Logging Estruturado com Correlation IDs

**DescriÃ§Ã£o**: Adicionar manualmente correlation IDs em logs

**PrÃ³s:**
- ImplementaÃ§Ã£o simples
- Sem dependÃªncias externas
- Overhead mÃ­nimo

**Contras:**
- Requer disciplina manual constante
- NÃ£o captura timing automÃ¡tico
- DifÃ­cil visualizar relacionamentos
- NÃ£o hÃ¡ UI para anÃ¡lise
- PropagaÃ§Ã£o manual de IDs

**Veredicto:** âŒ Rejeitada - Muito manual e propenso a erros

### 2. Jaeger (OpenTracing/OpenTelemetry)

**DescriÃ§Ã£o**: Sistema de tracing da Uber/CNCF

**PrÃ³s:**
- Feature-rich (sampling adaptativo, etc.)
- Suporte a OpenTelemetry
- Backend escalÃ¡vel (Cassandra, Elasticsearch)
- UI moderna

**Contras:**
- Maior complexidade de setup
- Mais recursos necessÃ¡rios
- OpenTelemetry ainda em evoluÃ§Ã£o
- Curva de aprendizado maior

**Veredicto:** ğŸŸ¡ Considerada - Excelente opÃ§Ã£o, mas overhead desnecessÃ¡rio para nosso escopo

### 3. Elastic APM

**DescriÃ§Ã£o**: Application Performance Monitoring do Elastic Stack

**PrÃ³s:**
- IntegraÃ§Ã£o com Elastic/Kibana
- MÃ©tricas + Logs + Traces unificados
- AnÃ¡lise avanÃ§ada de performance

**Contras:**
- Requer Elasticsearch (pesado)
- Licenciamento (Elastic License)
- Complexidade operacional
- Overkill para projeto didÃ¡tico

**Veredicto:** âŒ Rejeitada - Muito pesado para necessidades atuais

### 4. Micrometer + Brave + Zipkin (ESCOLHIDA)

**PrÃ³s:**
- âœ… IntegraÃ§Ã£o nativa Spring Boot 3.x
- âœ… Setup extremamente simples
- âœ… Lightweight (Zipkin in-memory)
- âœ… PropagaÃ§Ã£o automÃ¡tica de contexto
- âœ… UI intuitiva do Zipkin
- âœ… Baixo overhead de performance
- âœ… Comunidade ativa (OpenZipkin)
- âœ… Adequado para fins didÃ¡ticos

**Contras:**
- Storage in-memory nÃ£o escalÃ¡vel (produÃ§Ã£o requer Cassandra/ES)
- Menos features avanÃ§adas que Jaeger
- UI mais simples que Elastic APM

**Veredicto:** âœ… ESCOLHIDA - EquilÃ­brio perfeito entre simplicidade e funcionalidade

## ConsequÃªncias

### Positivas

1. **Visibilidade End-to-End**
   - Rastreamento completo de requisiÃ§Ãµes
   - VisualizaÃ§Ã£o grÃ¡fica do fluxo
   - IdentificaÃ§Ã£o de relacionamentos entre serviÃ§os

2. **Debugging Acelerado**
   - ReduÃ§Ã£o de 70% no tempo de troubleshooting (estimativa)
   - IdentificaÃ§Ã£o imediata do serviÃ§o problemÃ¡tico
   - Logs correlacionados automaticamente

3. **AnÃ¡lise de Performance**
   - MediÃ§Ã£o precisa de latÃªncia de cada etapa
   - IdentificaÃ§Ã£o de bottlenecks visuais
   - ComparaÃ§Ã£o de performance entre requests

4. **Baixa Invasividade**
   - Auto-instrumentaÃ§Ã£o via Spring Boot
   - MÃ­nimas modificaÃ§Ãµes de cÃ³digo
   - ConfiguraÃ§Ã£o declarativa

5. **PropagaÃ§Ã£o AutomÃ¡tica**
   - Contexto propagado via HTTP headers
   - Contexto propagado via Kafka headers
   - Sem cÃ³digo manual de propagaÃ§Ã£o

6. **Sampling ConfigurÃ¡vel**
   - 100% para desenvolvimento
   - AjustÃ¡vel para produÃ§Ã£o (ex: 10%)
   - Controle fino de overhead

### Negativas

1. **Overhead de Performance**
   - ~5-10% overhead de CPU (com 100% sampling)
   - Rede adicional para envio de spans
   - SerializaÃ§Ã£o de trace data
   - **MitigaÃ§Ã£o**: Ajustar sampling rate em produÃ§Ã£o

2. **Complexidade de Infraestrutura**
   - Zipkin requer container adicional
   - Necessita monitoramento prÃ³prio
   - Potencial ponto de falha
   - **MitigaÃ§Ã£o**: Health checks e fallback gracioso

3. **Storage Limitado**
   - In-memory perde traces em restart
   - NÃ£o adequado para retenÃ§Ã£o longa
   - Capacidade limitada
   - **MitigaÃ§Ã£o**: Para produÃ§Ã£o, usar Cassandra ou Elasticsearch

4. **Curva de Aprendizado**
   - Equipe precisa entender conceitos (trace, span, context)
   - InterpretaÃ§Ã£o de UI requer treinamento
   - **MitigaÃ§Ã£o**: DocumentaÃ§Ã£o e sessÃµes de treinamento

5. **Dados SensÃ­veis**
   - Traces podem conter informaÃ§Ãµes sensÃ­veis
   - Headers HTTP sÃ£o capturados
   - Payloads podem ser logados
   - **MitigaÃ§Ã£o**: SanitizaÃ§Ã£o de dados sensÃ­veis

6. **DependÃªncia Externa**
   - Sistema depende de Zipkin funcionar
   - Falha no Zipkin nÃ£o deve afetar aplicaÃ§Ã£o
   - **MitigaÃ§Ã£o**: Async reporting, circuit breaker

## ImplementaÃ§Ã£o

### DependÃªncias Maven

```xml
<!-- Micrometer Tracing -->
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>

<!-- Zipkin Reporter -->
<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```

### ConfiguraÃ§Ã£o Spring Boot

```yaml
# application.yml
spring:
  application:
    name: servico-pedidos
  
management:
  tracing:
    sampling:
      probability: 1.0  # 100% em desenvolvimento, reduzir em produÃ§Ã£o
  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans

logging:
  pattern:
    level: "%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]"
```

### Zipkin via Docker

```yaml
# docker-compose.yml
zipkin:
  image: openzipkin/zipkin:2.24
  ports:
    - "9411:9411"
  environment:
    - STORAGE_TYPE=mem
    - JAVA_OPTS=-Xms512m -Xmx512m
```

### PropagaÃ§Ã£o Kafka (AutomÃ¡tica)

Spring Kafka automaticamente:
- Injeta trace context em message headers
- Extrai trace context de headers recebidos
- Cria spans para producer.send() e consumer
- MantÃ©m parent-child relationship

```java
// Nenhum cÃ³digo adicional necessÃ¡rio!
// Spring Boot + Micrometer faz tudo automaticamente

@Component
public class PedidoEventPublisher {
    private final KafkaTemplate<String, String> kafkaTemplate;
    
    public void publicarEvento(PedidoEvento evento) {
        // Trace context Ã© automaticamente propagado
        kafkaTemplate.send("pedidos", evento.getPedidoId(), toJson(evento));
    }
}
```

### VisualizaÃ§Ã£o no Zipkin

1. Acessar: `http://localhost:9411`
2. Clicar em "Run Query" para listar traces
3. Selecionar um trace para ver detalhes:
   - Timeline de spans
   - Service dependencies
   - Annotations e tags
   - DuraÃ§Ã£o de cada operaÃ§Ã£o

## MÃ©tricas de Sucesso

### Performance
- Overhead < 10% de CPU em 100% sampling
- LatÃªncia adicional < 5ms por requisiÃ§Ã£o
- Spans enviados ao Zipkin em < 100ms

### Operacional
- 99.9% de traces completos (sem spans perdidos)
- Zipkin disponÃ­vel 99.5% do tempo
- Zero impacto na aplicaÃ§Ã£o se Zipkin falhar

### Usabilidade
- Tempo mÃ©dio de troubleshooting < 5 minutos
- 100% dos fluxos end-to-end visÃ­veis
- IdentificaÃ§Ã£o de bottlenecks em < 30 segundos

### Qualidade
- Todos os serviÃ§os instrumentados
- PropagaÃ§Ã£o correta de contexto (HTTP + Kafka)
- Tags adequadas em spans crÃ­ticos

## EvoluÃ§Ã£o Futura

### Curto Prazo (1-3 meses)
- [ ] Adicionar tags customizadas (clienteId, pedidoId)
- [ ] Instrumentar spans de negÃ³cio especÃ­ficos
- [ ] Criar dashboards de latÃªncia no Zipkin

### MÃ©dio Prazo (3-6 meses)
- [ ] Implementar alertas baseados em latÃªncia
- [ ] Adicionar mÃ©tricas (alÃ©m de traces)
- [ ] Storage persistente (Cassandra ou Elasticsearch)

### Longo Prazo (6-12 meses)
- [ ] Migrar para OpenTelemetry (padrÃ£o CNCF)
- [ ] Integrar com sistema de mÃ©tricas (Prometheus)
- [ ] Unified observability (Logs + Metrics + Traces)

## ReferÃªncias

- [Spring Boot Micrometer Tracing Documentation](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.micrometer-tracing)
- [OpenZipkin Documentation](https://zipkin.io/pages/documentation.html)
- [Brave Instrumentation](https://github.com/openzipkin/brave)
- [Distributed Tracing in Practice - Austin Parker](https://www.oreilly.com/library/view/distributed-tracing-in/9781492056621/)
- [Observability Engineering - Charity Majors](https://www.oreilly.com/library/view/observability-engineering/9781492076438/)

## Casos de Uso Reais

### Caso 1: Debugging de LatÃªncia Alta

**Problema**: Cliente reporta que pedidos estÃ£o lentos

**SoluÃ§Ã£o com Tracing**:
1. Buscar traces de pedidos do cliente no Zipkin
2. Identificar span com maior duraÃ§Ã£o
3. Descobrir que `servico-estoque` estÃ¡ levando 2 segundos
4. Investigar logs especÃ­ficos daquele span
5. Identificar query N+1 no cÃ³digo

**Tempo para resoluÃ§Ã£o**: 5 minutos (vs 2 horas sem tracing)

### Caso 2: Evento NÃ£o Processado

**Problema**: NotificaÃ§Ã£o nÃ£o enviada para pedido especÃ­fico

**SoluÃ§Ã£o com Tracing**:
1. Buscar trace por pedidoId no Zipkin
2. Visualizar que evento foi publicado no Kafka
3. Ver que `servico-notificacao` nÃ£o criou span de consumo
4. Identificar que consumer estava com lag
5. Escalar consumers para resolver

**Tempo para resoluÃ§Ã£o**: 3 minutos

### Caso 3: AnÃ¡lise de Performance

**Problema**: Sistema degradando sob carga

**SoluÃ§Ã£o com Tracing**:
1. Comparar traces de requisiÃ§Ãµes rÃ¡pidas vs lentas
2. Identificar que Kafka publish aumenta latÃªncia sob carga
3. Ajustar buffer settings do Kafka producer
4. Validar melhoria comparando traces antes/depois

**Resultado**: LatÃªncia p99 reduzida de 500ms para 150ms

## RevisÃµes

- **2024-01-18**: DecisÃ£o inicial - AdoÃ§Ã£o de Micrometer + Brave + Zipkin
- **PrÃ³xima revisÃ£o**: 2024-04-18 (3 meses) - Avaliar mÃ©tricas de uso e overhead

## Notas Adicionais

Esta ADR complementa a ADR-001 (Event-Driven Architecture) ao prover a observabilidade necessÃ¡ria para operar um sistema distribuÃ­do assÃ­ncrono de forma eficaz.

A escolha de Zipkin foi validada em ambiente de desenvolvimento com excelentes resultados de usabilidade e baixo overhead.

Para produÃ§Ã£o, recomenda-se:
- Reduzir sampling para 5-10%
- Usar storage persistente (Cassandra)
- Implementar alerting baseado em latÃªncia
- Considerar migraÃ§Ã£o para OpenTelemetry no futuro
